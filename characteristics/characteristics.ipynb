{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import util\n",
    "from pathlib import Path\n",
    "\n",
    "dic_reactive = {\n",
    "    \"patient_number_inactive\": [5,34,80,90,95,100,101,109,107,112,134,157,206,252,286,294,304,309,409,451,500,509\n",
    "                                ,514,546,633,673,706,736,762,771,777,868,903,916,923,942,960,979,982,1000,1008,1018\n",
    "                                ,1043,1045,1051,1058,1062,1064,1078,1098,1130,1146,1231,1265,1271,1295,1306,1322\n",
    "                                ,1328,1336,1363,1423,1429,1444,1467,1481], \n",
    "    \"patient_number_active\": [6,35,81,91,97,102,104,110,111,113,135,158,207,253,287,295,305,310,410,452,502,518,547\n",
    "                              ,634,674,707,738,763,772,778,870,917,924,944,962,980,984,1003,1009,1019,1044,1046\n",
    "                              ,1053,1060,1063,1066,1079,1100,1133,1147,1232,1266,1273,1297,1308,1325,1330,1337,1364\n",
    "                              ,1424,1430,1445,1468,1482]\n",
    "    \"col 2\": [10, 20, 30],\n",
    "    \"col 3\": list('xyz'),\n",
    "    \"col 4\": ['a', 'b', 'c'],\n",
    "    \"col 5\": pd.Series(range(3))\n",
    "}\n",
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/charlie/projects/entropy/preprocessed/canny/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/edge/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/edge/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/edge/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/edge/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/edge/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/edge/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/edge/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/gabor_edge/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/gabor_edge/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/gabor_edge/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/gabor_edge/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/gabor_edge/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/gabor_edge/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/canny/gabor_edge/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_otsu/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_otsu/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_otsu/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_otsu/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_otsu/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_otsu/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_otsu/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/otsu/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/otsu/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/otsu/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/otsu/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/otsu/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/otsu/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/otsu/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/mean/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/mean/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/mean/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/mean/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/mean/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/mean/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/mean/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_mean/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_mean/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_mean/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_mean/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_mean/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_mean/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_mean/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gaussmean/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gaussmean/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gaussmean/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gaussmean/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gaussmean/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gaussmean/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gaussmean/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_triangle/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_triangle/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_triangle/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_triangle/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_triangle/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_triangle/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/gabor_triangle/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/triangle/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/triangle/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/triangle/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/triangle/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/triangle/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/triangle/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/binary/triangle/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/gabor/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/gabor/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/gabor/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/gabor/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/gabor/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/gabor/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/gabor/gabor/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/gabor_faz/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/gabor_faz/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/gabor_faz/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/gabor_faz/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/gabor_faz/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/gabor_faz/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/gabor_faz/reactive/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/faz/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/faz/treatment/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/faz/treatment/active/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/faz/treatment/inactive/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/faz/reactive/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/faz/reactive/active/\n",
      "/home/charlie/projects/entropy/preprocessed/faz/faz/reactive/inactive/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n    if(dirname == \\'binary\\'):\\n    #第二層 列出前處理方式種類\\n        for dirname2 in os.listdir(pre_dir):\\n            if (dirname2.endswith(\".DS_store\")):\\n                continue\\n            \\n    if(dirname == \\'binary\\'):\\n    #第二層 列出前處理方式種類\\n        for dirname2 in os.listdir(pre_dir):\\n            if (dirname2.endswith(\".DS_store\")):\\n                continue\\n    \\n\\n# Define the directories to search for images\\ndirectories = [\\'/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/reactive/active/\\',\\n               \\'/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/reactive/inactive/\\',\\n               \\'/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/treatment/active/\\']\\n\\n# Create a dictionary to store the results\\nresults = {}\\n\\n# Loop over the directories and read the images\\nfor directory in directories:\\n    for filename in os.listdir(directory):\\n        if filename.endswith(\\'.jpg\\') or filename.endswith(\\'.png\\'):\\n            # Read the image and calculate the average intensity\\n            image = io.imread(os.path.join(directory, filename))\\n            average_intensity = np.mean(image)\\n            # Add the result to the dictionary\\n            results[(directory, filename, image.shape[0], image.shape[1])] = average_intensity\\n\\n# Convert the results dictionary to a DataFrame with a multi-level index\\ndf = pd.DataFrame.from_dict(results, orient=\\'index\\')\\ndf.index = pd.MultiIndex.from_tuples(df.index, names=[\\'Directory\\', \\'Filename\\', \\'Height\\', \\'Width\\'])\\n\\n# Pivot the DataFrame to have directory names as columns\\ndf = df.pivot_table(values=0, index=[\\'Filename\\', \\'Height\\', \\'Width\\'], columns=[\\'Directory\\'])\\n\\n# Save the results to an Excel file\\ndf.to_excel(\\'/home/charlie/projects/entropy/Entropy/excel/image_average_intensity.xlsx\\')\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import util\n",
    "import cv2\n",
    "\n",
    "\n",
    "parent_dir = r\"/home/charlie/projects/entropy/preprocessed/\"\n",
    "\n",
    "\n",
    "# Create dictionaries to store the results\n",
    "entropy = {}\n",
    "faz_area = {}\n",
    "faz_circularity = {}\n",
    "vessel_density = {}\n",
    "vessel_length_density = {}\n",
    "\n",
    "\n",
    "#第一層 列出前處理方式種類\n",
    "for dirname in os.listdir(parent_dir):\n",
    "    if (dirname.endswith(\".DS_store\")):\n",
    "        continue\n",
    "    \n",
    "    type_dir = parent_dir + dirname+'/'\n",
    "    print(type_dir)\n",
    "    \n",
    "    #第二層 列出前處理方式\n",
    "    for dirname1 in os.listdir(type_dir):\n",
    "        if (dirname1.endswith(\".DS_store\")):\n",
    "            continue\n",
    "        \n",
    "        pre_dir = type_dir + dirname1+'/'\n",
    "        print(pre_dir)\n",
    "        \n",
    "        #第三層 列出reactive/treatment\n",
    "        for dirname2 in os.listdir(pre_dir):\n",
    "            if (dirname2.endswith(\".DS_store\")):\n",
    "                continue\n",
    "            \n",
    "            cond_dir = pre_dir + dirname2+'/'\n",
    "            print(cond_dir)\n",
    "            \n",
    "            #第四層 列出active/inactive\n",
    "            for dirname3 in os.listdir(cond_dir):\n",
    "                if (dirname3.endswith(\".DS_Store\")):\n",
    "                    continue\n",
    "                    \n",
    "                amd_dir = cond_dir + dirname3+'/'\n",
    "                print(amd_dir)\n",
    "                \n",
    "                #列出目錄中的所有圖像\n",
    "                for filename in os.listdir(amd_dir):\n",
    "                    if not (filename.endswith(\".bmp\") or filename.endswith(\".jpg\")):\n",
    "                        continue\n",
    "                        \n",
    "                    # 組合文件路徑\n",
    "                    filepath = os.path.join(amd_dir, filename)\n",
    "                    image = cv2.imread(filepath)\n",
    "                    #print(filepath)\n",
    "                    \n",
    "                    #分類：binary\n",
    "                    if(dirname == 'binary'):\n",
    "                        #column名稱\n",
    "                        column_name = dirname1+ '_' + dirname3\n",
    "                        \n",
    "                        # Read the image and calculate the average intensity\n",
    "                        img_entropy = util.image_entropy(filepath)\n",
    "                        \n",
    "                        image_name = filename.split('_')\n",
    "                        # Add the result to the dictionary\n",
    "                        entropy[(column_name, image_name[0], image.shape[0], image.shape[1])] = img_entropy\n",
    "    \n",
    "# Convert the results dictionary to a DataFrame with a multi-level index\n",
    "df = pd.DataFrame.from_dict(entropy, orient='index')\n",
    "df.index = pd.MultiIndex.from_tuples(df.index, names=['Directory', 'Filename', 'Height', 'Width'])\n",
    "\n",
    "# Pivot the DataFrame to have directory names as columns\n",
    "df = df.pivot_table(values=0, index=['Filename', 'Height', 'Width'], columns=['Directory'])\n",
    "\n",
    "# Save the results to an Excel file\n",
    "df.to_excel('/home/charlie/projects/entropy/Entropy/excel/entropy.xlsx')\n",
    "            \n",
    "\n",
    "'''\n",
    "\n",
    "    if(dirname == 'binary'):\n",
    "    #第二層 列出前處理方式種類\n",
    "        for dirname2 in os.listdir(pre_dir):\n",
    "            if (dirname2.endswith(\".DS_store\")):\n",
    "                continue\n",
    "            \n",
    "    if(dirname == 'binary'):\n",
    "    #第二層 列出前處理方式種類\n",
    "        for dirname2 in os.listdir(pre_dir):\n",
    "            if (dirname2.endswith(\".DS_store\")):\n",
    "                continue\n",
    "    \n",
    "\n",
    "# Define the directories to search for images\n",
    "directories = ['/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/reactive/active/',\n",
    "               '/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/reactive/inactive/',\n",
    "               '/home/charlie/projects/entropy/preprocessed/binary/gabor_gaussmean/treatment/active/']\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop over the directories and read the images\n",
    "for directory in directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Read the image and calculate the average intensity\n",
    "            image = io.imread(os.path.join(directory, filename))\n",
    "            average_intensity = np.mean(image)\n",
    "            # Add the result to the dictionary\n",
    "            results[(directory, filename, image.shape[0], image.shape[1])] = average_intensity\n",
    "\n",
    "# Convert the results dictionary to a DataFrame with a multi-level index\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.index = pd.MultiIndex.from_tuples(df.index, names=['Directory', 'Filename', 'Height', 'Width'])\n",
    "\n",
    "# Pivot the DataFrame to have directory names as columns\n",
    "df = df.pivot_table(values=0, index=['Filename', 'Height', 'Width'], columns=['Directory'])\n",
    "\n",
    "# Save the results to an Excel file\n",
    "df.to_excel('/home/charlie/projects/entropy/Entropy/excel/image_average_intensity.xlsx')\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import util\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# 設置圖像目錄\n",
    "parent_dir = r\"/home/charlie/projects/entropy/preprocessed/binary/\"\n",
    "\n",
    "#第一層 列出前處理方式\n",
    "for dirname in os.listdir(parent_dir):\n",
    "    if (dirname.endswith(\".DS_store\")):\n",
    "        continue\n",
    "    \n",
    "    pre_dir = parent_dir + dirname+'/'\n",
    "    print(pre_dir)\n",
    "    \n",
    "    #第二層 列出reactive/treatment\n",
    "    for dirname2 in os.listdir(pre_dir):\n",
    "        if (dirname2.endswith(\".DS_store\")):\n",
    "            continue\n",
    "        \n",
    "        cond_dir = pre_dir + dirname2+'/'\n",
    "        print(cond_dir)\n",
    "        \n",
    "        #第三層 列出active/inactive\n",
    "        for dirname3 in os.listdir(cond_dir):\n",
    "            if (dirname3.endswith(\".DS_Store\")):\n",
    "                continue\n",
    "                \n",
    "            amd_dir = cond_dir + dirname3+'/'\n",
    "            print(amd_dir)\n",
    "            \n",
    "            #列出目錄中的所有圖像\n",
    "            for filename in os.listdir(amd_dir):\n",
    "                if not (filename.endswith(\".bmp\") or filename.endswith(\".jpg\")):\n",
    "                    continue\n",
    "                    \n",
    "                # 組合文件路徑\n",
    "                filepath = os.path.join(amd_dir, filename)\n",
    "                #print(filepath)\n",
    "                \n",
    "                # 讀取圖像\n",
    "                img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                #宣告process種類\n",
    "                processes = [('skeletonize', util.do_skeletonize),\n",
    "                            ('findlarge', util.do_findlarge)]\n",
    "                \n",
    "                for process_name, process in processes:\n",
    "                    #宣告資料夾名稱\n",
    "                    mypath = dirname+ '_'\n",
    "                    mypath += process_name\n",
    "                    \n",
    "                    #製造資料夾\n",
    "                    imgdir_path = f'/home/charlie/projects/entropy/processed/{mypath}/{dirname2}/{dirname3}/'\n",
    "                    try:\n",
    "                        os.makedirs(imgdir_path)\n",
    "                    # 資料夾已存在的例外處理\n",
    "                    except FileExistsError:\n",
    "                        print(\"資料夾已存在。\")\n",
    "\n",
    "                    #檔案存檔\n",
    "                    img_path = imgdir_path + filename\n",
    "                    img_path2 = Path(imgdir_path + filename)\n",
    "                    if img_path2.exists():\n",
    "                        print('檔案已存在')\n",
    "                        continue\n",
    "                    \n",
    "                    #進行處理\n",
    "                    img_pro = process(img)\n",
    "                    print(img_path)\n",
    "                    cv2.imwrite(img_path,  img_pro)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34747cd2c38f1d7760c39bad676fae01c81c3f9ed55bfb80b18cf5cc6926b871"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
